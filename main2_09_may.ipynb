{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932d5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import numpy as np \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling \n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import mlflow.pytorch\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU\n",
    "from torch_geometric.nn import TransformerConv, GATConv, TopKPooling, BatchNorm\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn.conv.x_conv import XConv\n",
    "import torch \n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
    "    accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import mlflow.pytorch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7ddb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6276b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab461a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.11.0\n",
      "Cuda available: True\n",
      "Torch geometric version: 2.0.5.dev20220428\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35bff41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path_temp= \"dataset-call-graph-blogpost-material/dataset/\"\n",
    "good_data=pickle.load(open(path_temp+\"goodware_graphs.p\",\"rb\"))\n",
    "bad_data=pickle.load(open(path_temp+\"malware_graphs.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4f8dd",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16078f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, root, filename,good_data, bad_data, test=False, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        root = Where the dataset should be stored. This folder is split\n",
    "        into raw_dir (downloaded dataset) and processed_dir (processed data). \n",
    "        \"\"\"\n",
    "        self.test = test\n",
    "        self.filename = filename\n",
    "        self.good_data=good_data\n",
    "        self.bad_data=bad_data\n",
    "        super(MoleculeDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data_passed=self.good_data+self.bad_data\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
    "            (The download func. is not implemented here)  \n",
    "        \"\"\"\n",
    "        return [\"goodware_graphs.p\",\"malware_graphs.p\"]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n",
    "#         self.data = self.data_passed\n",
    "        return \"NOt implemented yet\"\n",
    "\n",
    "        # if self.test:\n",
    "        #     return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
    "        # else:\n",
    "        #     return [f'data_{i}.pt' for i in list(self.data.index)]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "#         self.data = self.data_passed\n",
    "        print(\"started doing stuff\")\n",
    "        index=0\n",
    "\n",
    "        for mol in (self.good_data):\n",
    "            \n",
    "\n",
    "            feature_data=mol[0]\n",
    "            neighbour_data=mol[1]\n",
    "\n",
    "            # i need to create inst ->index\n",
    "            instr_index=dict()\n",
    "            for a,b in enumerate(feature_data):\n",
    "              instr_index[b]=a \n",
    "\n",
    "            # Get node features\n",
    "            node_feats = self._get_node_features(feature_data,instr_index)\n",
    "            # Get edge features\n",
    "            edge_feats = self._get_edge_features(neighbour_data)\n",
    "#             edge_feats = []\n",
    "            # Get adjacency info\n",
    "            edge_index = self._get_adjacency_info(neighbour_data,instr_index)\n",
    "\n",
    "            # Get labels info\n",
    "            label = 1\n",
    "\n",
    "            # Create data object\n",
    "            data = Data(x=node_feats, \n",
    "                        edge_index=edge_index,\n",
    "                        edge_attr=edge_feats,\n",
    "                        y=label,\n",
    "                        smiles=mol\n",
    "                        ) \n",
    "                        \n",
    "            torch.save(data, \n",
    "                    os.path.join(self.processed_dir, \n",
    "                                 f'data_{index}.pt'))\n",
    "\n",
    "            index+=1\n",
    "        \n",
    "        for mol in (self.bad_data):\n",
    "            \n",
    "\n",
    "            feature_data=mol[0]\n",
    "            neighbour_data=mol[1]\n",
    "\n",
    "            # i need to create inst ->index\n",
    "            instr_index=dict()\n",
    "            for a,b in enumerate(feature_data):\n",
    "              instr_index[b]=a \n",
    "\n",
    "            # Get node features\n",
    "            node_feats = self._get_node_features(feature_data,instr_index)\n",
    "            # Get edge features\n",
    "            edge_feats = self._get_edge_features(neighbour_data)\n",
    "#             edge_feats = []\n",
    "            # Get adjacency info\n",
    "            edge_index = self._get_adjacency_info(neighbour_data,instr_index)\n",
    "\n",
    "            # Get labels info\n",
    "            label = 0\n",
    "\n",
    "            # Create data object\n",
    "            data = Data(x=node_feats, \n",
    "                        edge_index=edge_index,\n",
    "                        edge_attr=edge_feats,\n",
    "                        y=label,\n",
    "                        smiles=mol\n",
    "                        ) \n",
    "                        \n",
    "            torch.save(data, \n",
    "                    os.path.join(self.processed_dir, \n",
    "                                 f'data_{index}.pt'))\n",
    "\n",
    "            index+=1\n",
    "        \n",
    "        \n",
    "\n",
    "    def process_node_features(self,val, node_feature_menu):\n",
    "      # print(\"jj\")\n",
    "      # print(val)\n",
    "      node_out=[]\n",
    "      keys=val.keys()\n",
    "      for name in node_feature_menu : \n",
    "        if(name in keys):\n",
    "          node_out.append(val[name])\n",
    "        else:\n",
    "          node_out.append(0)\n",
    "      return node_out\n",
    "\n",
    "\n",
    "    def _get_node_features(self, node_features,instr_index):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of Nodes, Node Feature size]\n",
    "        \"\"\"\n",
    "        node_feature_menu=['mov', 'call', 'lea', 'jmp', 'push', 'add', 'xor', 'cmp', 'int3', 'nop', 'pushl', 'dec', 'sub', 'insl', 'inc','jz', 'jnz', 'je', 'jne', 'ja', 'jna', 'js', 'jns', 'jl', 'jnl', 'jg', 'jng']\n",
    "\n",
    "        all_node_feats = []\n",
    "\n",
    "        for atom in node_features:\n",
    "            # print(\"atom is\",atom)\n",
    "            \n",
    "            node_feats = []\n",
    "            node_feats = self.process_node_features(node_features[atom],node_feature_menu)\n",
    "            # Append node features to matrix\n",
    "            all_node_feats.append(node_feats)\n",
    "\n",
    "        all_node_feats = np.asarray(all_node_feats)\n",
    "        # all_node_feats = np.transpose(all_node_feats)\n",
    "        return torch.tensor(all_node_feats, dtype=torch.float)\n",
    "\n",
    "    def _get_edge_features(self, mol):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of edges, Edge Feature size]\n",
    "        \"\"\"\n",
    "        all_edge_feats = []\n",
    "\n",
    "        # for bond in mol.GetBonds():\n",
    "        #     edge_feats = []\n",
    "        #     # Feature 1: Bond type (as double)\n",
    "        #     edge_feats.append(bond.GetBondTypeAsDouble())\n",
    "        #     # Feature 2: Rings\n",
    "        #     edge_feats.append(bond.IsInRing())\n",
    "        #     # Append node features to matrix (twice, per direction)\n",
    "        #     all_edge_feats += [edge_feats, edge_feats]\n",
    "\n",
    "        all_edge_feats = np.asarray(all_edge_feats)\n",
    "        return torch.tensor(all_edge_feats, dtype=torch.float)\n",
    "\n",
    "    def get_one_instr_adjacency(self,val,instr_index,self_instruction_number):\n",
    "        edge_val=[]\n",
    "        for a in val:\n",
    "            edge_val+=[[instr_index[self_instruction_number],instr_index[a]]]\n",
    "\n",
    "        return edge_val\n",
    "\n",
    "    def _get_adjacency_info(self, mol, instr_index):\n",
    "        \"\"\"\n",
    "        We could also use rdmolops.GetAdjacencyMatrix(mol)\n",
    "        but we want to be sure that the order of the indices\n",
    "        matches the order of the edge features\n",
    "        \"\"\"\n",
    "        edge_indices = []\n",
    "        for bond in mol:\n",
    "            edge_indices += self.get_one_instr_adjacency(mol[bond],instr_index,bond)\n",
    "\n",
    "        # print(\"--------\")\n",
    "        # print(len(edge_indices))\n",
    "        # print(len(edge_indices[0]))\n",
    "        # print(len(edge_indices[1]))\n",
    "        # print(edge_indices)\n",
    "        # edge_indices = torch.tensor(edge_indices)\n",
    "        # edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
    "\n",
    "        np_edge=np.array(edge_indices)\n",
    "        np_edge=np.transpose(np_edge)\n",
    "        tr_edge=torch.tensor(np_edge, dtype=torch.long)\n",
    "\n",
    "\n",
    "        return tr_edge\n",
    "\n",
    "    def _get_labels(self, label):\n",
    "        label = np.asarray([label])\n",
    "        return torch.tensor(label, dtype=torch.int64)\n",
    "\n",
    "    def len(self):\n",
    "#         return self.data_pass.shape[0]\n",
    "        return len(self.data_passed)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
    "            - Is not needed for PyG's InMemoryDataset\n",
    "        \"\"\"\n",
    "        data = torch.load(os.path.join(self.processed_dir, \n",
    "                             f'data_{idx}.pt'))\n",
    "        return data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fbe3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started doing stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = MoleculeDataset(root=\"data/\", filename=\"goodware_graphs.p\", good_data=good_data[:100], bad_data=bad_data[:100])\n",
    "train_dataset = MoleculeDataset(root=\"data/\", filename=\"goodware_graphs.p\", good_data=good_data, bad_data=bad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a1b62b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1199, 27], edge_index=[2, 3230], edge_attr=[0], y=0, smiles=[2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)\n",
    "train_dataset[546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5691fc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "566+526\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95646eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cut_dataset=train_dataset[526:566]\n",
    "train_cut_dataset= train_dataset[:526]+train_dataset[566:1092]\n",
    "# train_cut_dataset= train_dataset[:526]+train_dataset[566:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f1dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b859ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "NUM_GRAPHS_PER_BATCH = 30\n",
    "\n",
    "train_loader = DataLoader(train_cut_dataset, \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH,\n",
    "                     shuffle=True,\n",
    "                         num_workers=0)\n",
    "test_loader = DataLoader(test_cut_dataset, \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH,\n",
    "                     shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c55309",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69ffcaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(GNN, self).__init__()\n",
    "        num_classes = 2\n",
    "        embedding_size = 128\n",
    "\n",
    "        # GNN layers\n",
    "        self.conv1 = GATConv(feature_size, embedding_size, heads=3, dropout=0.3)\n",
    "        self.conv2 = GATConv(embedding_size*3, embedding_size, heads=3, dropout=0.3)\n",
    "        self.conv3 = GATConv(embedding_size*3,2, heads=1, dropout=0.3)\n",
    "        # self.readout = GlobalMeanPool()\n",
    "\n",
    "    # def forward(self, x, edge_attr, edge_index, batch):\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # x, edge_index, batch = self.arguments_read(*args, **kwargs)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        # x = x.mean(dim=1)  # 464\n",
    "        x = x.mean(dim=0)  # 2\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d3361c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GNNPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "class GlobalMeanPool(GNNPool):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, batch):\n",
    "        return gnn.global_mean_pool(x, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ccdbe958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10927db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 160902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (conv1): GATConv(27, 128, heads=3)\n",
       "  (conv2): GATConv(384, 128, heads=3)\n",
       "  (conv3): GATConv(384, 2, heads=1)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Loading the model\n",
    "# model = GNN(feature_size=train_dataset[0].x.shape[0]) \n",
    "model = GNN(feature_size=train_dataset[0].x.shape[1]) \n",
    "model = model.to(device)\n",
    "print(f\"Number of parameters: {count_parameters(model)}\")\n",
    "weights = torch.tensor([1, 1], dtype=torch.float32).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.2, amsgrad=False)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.008)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148a343d",
   "metadata": {},
   "source": [
    "# train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9689160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)  \n",
    "        pred = model(batch.x.float(), \n",
    "                        # batch.edge_attr.float(),\n",
    "                        batch.edge_index, \n",
    "                        batch.batch\n",
    "                        ) \n",
    "        loss = torch.sqrt(loss_fn(pred, batch.y))    \n",
    "        all_preds.append(np.argmax(pred.cpu().detach().numpy(), axis=1))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"test\")\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calculate_metrics(y_pred, y_true, epoch, type):\n",
    "    print(f\"\\n Confusion matrix: \\n {confusion_matrix(y_pred, y_true)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_pred, y_true)}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_pred, y_true)}\")\n",
    "    print(f\"Precision: {precision_score(y_pred, y_true)}\")\n",
    "    print(f\"Recall: {recall_score(y_pred, y_true)}\")\n",
    "    try:\n",
    "        roc = roc_auc_score(y_pred, y_true)\n",
    "        print(f\"ROC AUC: {roc}\")\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(roc), step=epoch)\n",
    "    except:\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(0), step=epoch)\n",
    "        print(f\"ROC AUC: notdefined\")\n",
    "        \n",
    "    try:\n",
    "        mlflow.log_metric(key=f\"accuracy-{type}\", value=float(accuracy_score(y_pred, y_true)), step=epoch)\n",
    "    except:\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(0), step=epoch)\n",
    "        print(f\"Accuracy: notdefined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e09eaccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    # Enumerate over the data\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for _, batch in enumerate(tqdm(train_loader)):\n",
    "        # Use GPU\n",
    "        # print(\"--------------------------------------------------\")\n",
    "        batch.to(device)  \n",
    "        # Reset gradients\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        # Passing the node features and the connection info\n",
    "        pred = model(batch.x.float(), \n",
    "                                # batch.edge_attr.float(),\n",
    "                                batch.edge_index, \n",
    "                                batch.batch\n",
    "                                ) \n",
    "        pred=pred.resize(1,pred.size()[0])\n",
    "        # Calculating the loss and gradients\n",
    "        #  loss = torch.sqrt(loss_fn(pred, batch.y))\n",
    " \n",
    "        # pred=pred.resize(1,pred.size()[0])\n",
    "        sfm = nn.Softmax(dim=1)\n",
    "        pred=sfm(pred) \n",
    "        \n",
    "        # print(\"predictions\",pred)\n",
    "\n",
    "        # pred=pred.data.argmax()\n",
    "        # print(\"predictions\",pred.size())\n",
    "        # print(\"predictions\",pred.size())\n",
    "\n",
    "\n",
    "        loss_v1 =  loss_fn(pred, batch.y) \n",
    "        # print(\"loss_v1\",loss_v1)\n",
    "        loss_v2=torch.sqrt(loss_v1)\n",
    "        # print(\"loss_v2\",loss_v2)\n",
    "        loss=loss_v2\n",
    "        \n",
    "        loss.backward()  \n",
    "\n",
    "        \n",
    "        # this is the additional clipping\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=7.0)\n",
    "        \n",
    "        \n",
    "        # Update using the gradients\n",
    "        optimizer.step()  \n",
    "\n",
    "\n",
    "        all_preds.append(np.argmax(pred.cpu().detach().numpy(), axis=1))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036bec8f",
   "metadata": {},
   "source": [
    "# lets train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a7f9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import TransformerConv, GATConv, TopKPooling, BatchNorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac796c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [02:06<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[489 182]\n",
      " [326 364]]\n",
      "F1 Score: 0.5889967637540452\n",
      "Accuracy: 0.6267450404114622\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.527536231884058\n",
      "ROC AUC: 0.628149636061254\n",
      "Epoch 0 | Train Loss 0.5783620476722717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [01:36<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[812 546]\n",
      " [  3   0]]\n",
      "F1 Score: 0.0\n",
      "Accuracy: 0.5966201322556943\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "ROC AUC: 0.29896907216494845\n",
      "Epoch 1 | Train Loss 0.5844274163246155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [01:35<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[813 546]\n",
      " [  2   0]]\n",
      "F1 Score: 0.0\n",
      "Accuracy: 0.5973548861131521\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "ROC AUC: 0.29911699779249445\n",
      "Epoch 2 | Train Loss 0.568854808807373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [01:36<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[814 546]\n",
      " [  1   0]]\n",
      "F1 Score: 0.0\n",
      "Accuracy: 0.5980896399706098\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "ROC AUC: 0.29926470588235293\n",
      "Epoch 3 | Train Loss 0.5918329954147339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [01:35<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[814 546]\n",
      " [  1   0]]\n",
      "F1 Score: 0.0\n",
      "Accuracy: 0.5980896399706098\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "ROC AUC: 0.29926470588235293\n",
      "Epoch 4 | Train Loss 0.5751984119415283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [01:36<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[814 545]\n",
      " [  1   1]]\n",
      "F1 Score: 0.0036496350364963502\n",
      "Accuracy: 0.5988243938280676\n",
      "Precision: 0.0018315018315018315\n",
      "Recall: 0.5\n",
      "ROC AUC: 0.549484915378955\n",
      "Epoch 5 | Train Loss 0.568277895450592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [01:36<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[815 545]\n",
      " [  0   1]]\n",
      "F1 Score: 0.003656307129798903\n",
      "Accuracy: 0.5995591476855253\n",
      "Precision: 0.0018315018315018315\n",
      "Recall: 1.0\n",
      "ROC AUC: 0.7996323529411764\n",
      "Epoch 6 | Train Loss 0.5698463916778564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [01:36<00:00, 14.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[815 545]\n",
      " [  0   1]]\n",
      "F1 Score: 0.003656307129798903\n",
      "Accuracy: 0.5995591476855253\n",
      "Precision: 0.0018315018315018315\n",
      "Recall: 1.0\n",
      "ROC AUC: 0.7996323529411764\n",
      "Epoch 7 | Train Loss 0.5714676380157471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [01:36<00:00, 14.16it/s]\n",
      "d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[815 546]\n",
      " [  0   0]]\n",
      "F1 Score: 0.0\n",
      "Accuracy: 0.5988243938280676\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "ROC AUC: notdefined\n",
      "Epoch 8 | Train Loss 0.5782056450843811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [01:36<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[815 545]\n",
      " [  0   1]]\n",
      "F1 Score: 0.003656307129798903\n",
      "Accuracy: 0.5995591476855253\n",
      "Precision: 0.0018315018315018315\n",
      "Recall: 1.0\n",
      "ROC AUC: 0.7996323529411764\n",
      "Epoch 9 | Train Loss 0.5685959458351135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1361 [00:00<?, ?it/s]d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:549: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 1361/1361 [01:36<00:00, 14.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[815 545]\n",
      " [  0   1]]\n",
      "F1 Score: 0.003656307129798903\n",
      "Accuracy: 0.5995591476855253\n",
      "Precision: 0.0018315018315018315\n",
      "Recall: 1.0\n",
      "ROC AUC: 0.7996323529411764\n",
      "Epoch 10 | Train Loss 0.5706748366355896\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\main2_09_may.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000019?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000019?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m epoch \u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000019?line=14'>15</a>\u001b[0m     loss \u001b[39m=\u001b[39m test(epoch\u001b[39m=\u001b[39;49mepoch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000019?line=15'>16</a>\u001b[0m     \u001b[39m# loss = loss.detach().gpu().numpy()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000019?line=16'>17</a>\u001b[0m     \u001b[39m# loss = loss.detach().numpy()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000019?line=17'>18</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[1;32md:\\code\\OELP_bigger\\main2_09_may.ipynb Cell 16'\u001b[0m in \u001b[0;36mtest\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000015?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000015?line=4'>5</a>\u001b[0m     batch\u001b[39m.\u001b[39mto(device)  \n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000015?line=5'>6</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(batch\u001b[39m.\u001b[39;49mx\u001b[39m.\u001b[39;49mfloat(), \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000015?line=6'>7</a>\u001b[0m                     batch\u001b[39m.\u001b[39;49medge_attr\u001b[39m.\u001b[39;49mfloat(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000015?line=7'>8</a>\u001b[0m                     batch\u001b[39m.\u001b[39;49medge_index, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000015?line=8'>9</a>\u001b[0m                     batch\u001b[39m.\u001b[39;49mbatch\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000015?line=9'>10</a>\u001b[0m                     ) \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000015?line=10'>11</a>\u001b[0m     loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(loss_fn(pred, batch\u001b[39m.\u001b[39my))    \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000015?line=11'>12</a>\u001b[0m     all_preds\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39margmax(pred\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Run the training\n",
    "with mlflow.start_run() as run:\n",
    "    for epoch in range(20):\n",
    "        # Training\n",
    "        model.train()\n",
    "        loss = train(epoch=epoch)\n",
    "        # loss = loss.detach().gpu().numpy()\n",
    "        loss = loss.detach().cpu().numpy()\n",
    "        print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
    "        mlflow.log_metric(key=\"Train loss\", value=float(loss), step=epoch)\n",
    "\n",
    "        # Testing\n",
    "        model.eval()\n",
    "        if epoch % 10 == 0 and epoch !=0:\n",
    "            loss = test(epoch=epoch)\n",
    "            # loss = loss.detach().gpu().numpy()\n",
    "            # loss = loss.detach().numpy()\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            print(f\"Epoch {epoch} | Test Loss {loss}\")\n",
    "            mlflow.log_metric(key=\"Test loss\", value=float(loss), step=epoch)\n",
    "\n",
    "        scheduler.step()\n",
    "print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3615ff6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0854, -0.3828, -0.8074,  0.5448,  1.0877]], requires_grad=True)\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(1, 5, requires_grad=True)\n",
    "target = torch.empty(1, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "\n",
    "# Example of target with class probabilities\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(input)\n",
    "print(target)\n",
    "# output = loss(input, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92973361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/04/28 23:57:54 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\JERRYJ~1\\AppData\\Local\\Temp\\tmpajrx1zfm\\model\\data, flavor: pytorch), fall back to return ['torch==1.11.0', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback.\n",
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "# %% Save the model \n",
    "model_type_name=\"20epoch_gpu\"\n",
    "\n",
    "mlflow.pytorch.log_model(model, \"model\") \n",
    "mlflow.end_run()\n",
    "\n",
    "\n",
    "# SAVE MODEL\n",
    "#  pls create a folder named model_saved if not there\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d_%m_%Y %H_%M_%S\")\n",
    "PATH_to_save_model=\"model_saved/\"+\"model_\"+dt_string+\":\"+model_type_name+\".pt\"\n",
    "PATH_to_save_model=\"model_saved/model \"+dt_string+model_type_name+\".pt\"\n",
    "torch.save(model, PATH_to_save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa76746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_saved/model 28_04_2022 23_57_541epoch_cpu.pt'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_to_save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70addd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_to_save_model='model_saved/model 25_04_2022 13_52_341epoch_ennexp.pt'\n",
    "# PATH_to_save_model='model_saved/model 25_04_2022 14_50_061epoch_ennexp.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0de0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LOAD=\"model_saved/model 28_04_2022 23_57_541epoch_cpu.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4982651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (conv1): GATConv(27, 256, heads=3)\n",
       "  (head_transform1): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (pool1): TopKPooling(256, ratio=0.8, multiplier=1.0)\n",
       "  (conv2): GATConv(256, 256, heads=3)\n",
       "  (head_transform2): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (pool2): TopKPooling(256, ratio=0.5, multiplier=1.0)\n",
       "  (conv3): GATConv(256, 256, heads=3)\n",
       "  (head_transform3): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (pool3): TopKPooling(256, ratio=0.2, multiplier=1.0)\n",
       "  (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (linear3): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (linear4): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=torch.load(PATH_TO_LOAD)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08c1d145",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing rdBase: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\main2_09_may.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000027?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdig\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxgraph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmethod\u001b[39;00m \u001b[39mimport\u001b[39;00m SubgraphX\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000027?line=1'>2</a>\u001b[0m explainer \u001b[39m=\u001b[39m SubgraphX(model, num_classes\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, device\u001b[39m=\u001b[39mdevice, explain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000027?line=2'>3</a>\u001b[0m                         reward_method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnc_mc_l_shapley\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\dig\\xgraph\\method\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeeplift\u001b[39;00m \u001b[39mimport\u001b[39;00m DeepLIFT\n\u001b[0;32m      <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgnn_gi\u001b[39;00m \u001b[39mimport\u001b[39;00m GNN_GI\n\u001b[0;32m      <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgnn_lrp\u001b[39;00m \u001b[39mimport\u001b[39;00m GNN_LRP\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\dig\\xgraph\\method\\deeplift.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/deeplift.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m subgraph\n\u001b[0;32m      <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/deeplift.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdeeplift\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayer_deep_lift\u001b[39;00m \u001b[39mimport\u001b[39;00m DeepLift\n\u001b[1;32m----> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/deeplift.py?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase_explainer\u001b[39;00m \u001b[39mimport\u001b[39;00m WalkBase\n\u001b[0;32m      <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/deeplift.py?line=8'>9</a>\u001b[0m EPS \u001b[39m=\u001b[39m \u001b[39m1e-15\u001b[39m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/deeplift.py?line=11'>12</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDeepLIFT\u001b[39;00m(WalkBase):\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\dig\\xgraph\\method\\base_explainer.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/base_explainer.py?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_networkx\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/base_explainer.py?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m subgraph\n\u001b[1;32m---> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/base_explainer.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrdkit\u001b[39;00m \u001b[39mimport\u001b[39;00m Chem\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/base_explainer.py?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maxes\u001b[39;00m \u001b[39mimport\u001b[39;00m Axes\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/dig/xgraph/method/base_explainer.py?line=17'>18</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\rdkit\\__init__.py:38\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/rdkit/__init__.py?line=33'>34</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/rdkit/__init__.py?line=35'>36</a>\u001b[0m \u001b[39m# Need to import rdBase to properly wrap exceptions\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/rdkit/__init__.py?line=36'>37</a>\u001b[0m \u001b[39m# otherwise they will leak memory\u001b[39;00m\n\u001b[1;32m---> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/rdkit/__init__.py?line=37'>38</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m rdBase\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/rdkit/__init__.py?line=39'>40</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/rdkit/__init__.py?line=40'>41</a>\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrdBase\u001b[39;00m \u001b[39mimport\u001b[39;00m rdkitVersion \u001b[39mas\u001b[39;00m __version__\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing rdBase: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "from dig.xgraph.method import SubgraphX\n",
    "explainer = SubgraphX(model, num_classes=4, device=device, explain_graph=True, reward_method='nc_mc_l_shapley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00178d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dig.xgraph.method.subgraphx import find_closest_node_result\n",
    "plotutils = PlotUtils(dataset_name='ba_shapes')\n",
    "\n",
    "# Visualization\n",
    "max_nodes = 5\n",
    "node_idx = node_indices[20]\n",
    "print(f'explain graph node {node_idx}')\n",
    "data.to(device)\n",
    "logits = model(data.x, data.edge_index)\n",
    "prediction = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "_, explanation_results, related_preds = \\\n",
    "    explainer(data.x, data.edge_index, node_idx=node_idx, max_nodes=max_nodes)\n",
    "result = find_closest_node_result(explanation_results[prediction], max_nodes=max_nodes)\n",
    "\n",
    "plotutils = PlotUtils(dataset_name='ba_shapes')\n",
    "explainer.visualization(explanation_results,\n",
    "                        prediction,\n",
    "                        max_nodes=max_nodes,\n",
    "                        plot_utils=plotutils,\n",
    "                        y=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518dcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ca79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d487bbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GNNExplainer\n",
    "# Initialize explainer\n",
    "explainer = GNNExplainer(model, epochs=200, return_type='log_prob')\n",
    "graph = train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "05615959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1217])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.edge_index.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d2f6595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3f91660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\main2_09_may.ipynb Cell 43'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000034?line=0'>1</a>\u001b[0m \u001b[39m# node_feat_mask, edge_mask = explainer.explain_graph(graph.x, graph.edge_index, batch_index=1)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000034?line=1'>2</a>\u001b[0m \u001b[39m# node_feat_mask, edge_mask = explainer.explain_graph(graph.x, graph.edge_index, batch=3)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000034?line=2'>3</a>\u001b[0m \u001b[39m# node_feat_mask, edge_mask = explainaer.explain_graph(graph.x, graph.edge_index, edge_attr=2)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000034?line=3'>4</a>\u001b[0m node_feat_mask, edge_mask \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mexplain_graph(graph\u001b[39m.\u001b[39;49mx, graph\u001b[39m.\u001b[39;49medge_index)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\models\\gnn_explainer.py:167\u001b[0m, in \u001b[0;36mGNNExplainer.explain_graph\u001b[1;34m(self, x, edge_index, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/gnn_explainer.py?line=164'>165</a>\u001b[0m h \u001b[39m=\u001b[39m x \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_feat_mask\u001b[39m.\u001b[39msigmoid()\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/gnn_explainer.py?line=165'>166</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x\u001b[39m=\u001b[39mh, edge_index\u001b[39m=\u001b[39medge_index, batch\u001b[39m=\u001b[39mbatch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/gnn_explainer.py?line=166'>167</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_loss(out, prediction, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/gnn_explainer.py?line=167'>168</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/gnn_explainer.py?line=168'>169</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\models\\explainer.py:251\u001b[0m, in \u001b[0;36mExplainer.get_loss\u001b[1;34m(self, out, prediction, node_idx, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/explainer.py?line=248'>249</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/explainer.py?line=249'>250</a>\u001b[0m     log_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_log_prob(out)\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/explainer.py?line=250'>251</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss(log_logits, prediction, node_idx, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/explainer.py?line=251'>252</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\models\\gnn_explainer.py:110\u001b[0m, in \u001b[0;36mGNNExplainer._loss\u001b[1;34m(self, log_logits, prediction, node_idx)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/gnn_explainer.py?line=107'>108</a>\u001b[0m         loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mlog_logits[node_idx, prediction[node_idx]]\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/gnn_explainer.py?line=108'>109</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/gnn_explainer.py?line=109'>110</a>\u001b[0m         loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mlog_logits[\u001b[39m0\u001b[39m, prediction[\u001b[39m0\u001b[39;49m]]\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/gnn_explainer.py?line=111'>112</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_edge_mask:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/gnn_explainer.py?line=112'>113</a>\u001b[0m     m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_mask\u001b[39m.\u001b[39msigmoid()\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "# node_feat_mask, edge_mask = explainer.explain_graph(graph.x, graph.edge_index, batch_index=1)\n",
    "# node_feat_mask, edge_mask = explainer.explain_graph(graph.x, graph.edge_index, batch=3)\n",
    "# node_feat_mask, edge_mask = explainaer.explain_graph(graph.x, graph.edge_index, edge_attr=2)\n",
    "node_feat_mask, edge_mask = explainer.explain_graph(graph.x, graph.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 464]) torch.Size([2, 821])\n",
      "torch.Size([27, 492]) torch.Size([2, 1217])\n",
      "torch.Size([27, 485]) torch.Size([2, 925])\n",
      "torch.Size([27, 440]) torch.Size([2, 792])\n",
      "torch.Size([27, 465]) torch.Size([2, 836])\n",
      "torch.Size([27, 468]) torch.Size([2, 855])\n",
      "torch.Size([27, 440]) torch.Size([2, 792])\n",
      "torch.Size([27, 587]) torch.Size([2, 1083])\n",
      "torch.Size([27, 1137]) torch.Size([2, 3479])\n",
      "torch.Size([27, 478]) torch.Size([2, 866])\n",
      "torch.Size([27, 1024]) torch.Size([2, 2837])\n",
      "torch.Size([27, 481]) torch.Size([2, 690])\n",
      "torch.Size([27, 488]) torch.Size([2, 928])\n",
      "torch.Size([27, 322]) torch.Size([2, 354])\n",
      "torch.Size([27, 1122]) torch.Size([2, 2241])\n",
      "torch.Size([27, 559]) torch.Size([2, 982])\n",
      "torch.Size([27, 1643]) torch.Size([2, 4396])\n",
      "torch.Size([27, 568]) torch.Size([2, 1731])\n",
      "torch.Size([27, 463]) torch.Size([2, 816])\n",
      "torch.Size([27, 484]) torch.Size([2, 925])\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(train_dataset)):\n",
    "for i in range(20):\n",
    "    print(train_dataset[i].x.size(),train_dataset[i].edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d9439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 559, 560, 561],\n",
       "        [531, 546, 254,  ..., 120, 522, 523]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[i].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6e6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([464, 27])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dataset[i].x\n",
    "# len(train_dataset[i].x)\n",
    "# train_dataset[0].x.size()\n",
    "train_dataset[0].x.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17cb122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[i].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953eac84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[i].y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dcc67d",
   "metadata": {},
   "source": [
    "# GNN EXPLAINER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97e1936",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6fb0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv, GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61be65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16, normalize=False)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes, normalize=False)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46405409",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Cora'\n",
    "path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'Planetoid')\n",
    "transform = T.Compose([T.GCNNorm(), T.NormalizeFeatures()])\n",
    "dataset = Planetoid(path, dataset, transform=transform)\n",
    "data = dataset[0]\n",
    "\n",
    "# not ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "485cf98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=train_dataset\n",
    "dataset.num_classes=2\n",
    "data = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fc5f3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9e73e03",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'train_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:61\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/storage.py?line=59'>60</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/storage.py?line=60'>61</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/storage.py?line=61'>62</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:81\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/storage.py?line=79'>80</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m---> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/storage.py?line=80'>81</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'train_mask'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\main2_09_may.ipynb Cell 48'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000060?line=2'>3</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000060?line=3'>4</a>\u001b[0m log_logits \u001b[39m=\u001b[39m model(x, edge_index, edge_weight)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000060?line=4'>5</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnll_loss(log_logits[data\u001b[39m.\u001b[39;49mtrain_mask], data\u001b[39m.\u001b[39my[data\u001b[39m.\u001b[39mtrain_mask])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000060?line=5'>6</a>\u001b[0m \u001b[39m# loss = F.nll_loss(log_logits, data.y)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000060?line=6'>7</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:375\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/data.py?line=368'>369</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_store\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/data.py?line=369'>370</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/data.py?line=370'>371</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object was created by an older version of PyG. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/data.py?line=371'>372</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf this error occurred while loading an already existing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/data.py?line=372'>373</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdataset, remove the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprocessed/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directory in the dataset\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/data.py?line=373'>374</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mroot folder and try again.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/data.py?line=374'>375</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_store, key)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:63\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/storage.py?line=60'>61</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/storage.py?line=61'>62</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/storage.py?line=62'>63</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/data/storage.py?line=63'>64</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'train_mask'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    log_logits = model(x, edge_index, edge_weight)\n",
    "    loss = F.nll_loss(log_logits[data.train_mask], data.y[data.train_mask])\n",
    "    # loss = F.nll_loss(log_logits, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db8a1d",
   "metadata": {},
   "source": [
    "## GNN_EXplainer2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42c2050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BatchNorm1d, Linear, ReLU, Sequential\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINConv, global_add_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2afc4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, dim, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv4 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.conv5 = GINConv(\n",
    "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
    "                       Linear(dim, dim), ReLU()))\n",
    "\n",
    "        self.lin1 = Linear(dim, dim)\n",
    "        self.lin2 = Linear(dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af525ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61102d9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\main2_09_may.ipynb Cell 57'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000070?line=0'>1</a>\u001b[0m dataset\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed7ada7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device=\"cpu\"\n",
    "# model = Net(dataset.num_features, 256, dataset.num_classes).to(device)\n",
    "model = Net(27, 256, 2).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41c2f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EIther this or above\n",
    "# from config import HYPERPARAMETERS as params1 , BEST_PARAMETERS as params, SIGNATURE \n",
    "\n",
    "\n",
    "# weight = torch.tensor([params[\"pos_weight\"]], dtype=torch.float32).to(device)\n",
    "# loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), \n",
    "#                             lr=0.0001,\n",
    "#                             momentum=0.08,\n",
    "#                             weight_decay=0.0001)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "366e9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "\n",
    "\n",
    "        # this is the new loss function\n",
    "        # loss = loss_fn(torch.squeeze(output), data.y.float())\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73de2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        total_correct += int((out.argmax(-1) == data.y).sum())\n",
    "    return total_correct / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "158bfdee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([30])) must be the same as input size (torch.Size([30, 2]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\main2_09_may.ipynb Cell 62'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000055?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m101\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000055?line=1'>2</a>\u001b[0m     loss \u001b[39m=\u001b[39m train()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000055?line=2'>3</a>\u001b[0m     train_acc \u001b[39m=\u001b[39m test(train_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000055?line=3'>4</a>\u001b[0m     test_acc \u001b[39m=\u001b[39m test(test_loader)\n",
      "\u001b[1;32md:\\code\\OELP_bigger\\main2_09_may.ipynb Cell 60'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000053?line=7'>8</a>\u001b[0m output \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index, data\u001b[39m.\u001b[39mbatch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000053?line=8'>9</a>\u001b[0m \u001b[39m# loss = F.nll_loss(output, data.y)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000053?line=9'>10</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000053?line=10'>11</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000053?line=11'>12</a>\u001b[0m \u001b[39m# this is the new loss function\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000053?line=12'>13</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(torch\u001b[39m.\u001b[39;49msqueeze(output), data\u001b[39m.\u001b[39;49my\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000053?line=15'>16</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000053?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:713\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/loss.py?line=711'>712</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/loss.py?line=712'>713</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy_with_logits(\u001b[39minput\u001b[39;49m, target,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/loss.py?line=713'>714</a>\u001b[0m                                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/loss.py?line=714'>715</a>\u001b[0m                                               pos_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_weight,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/loss.py?line=715'>716</a>\u001b[0m                                               reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:3130\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/functional.py?line=3126'>3127</a>\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/functional.py?line=3128'>3129</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (target\u001b[39m.\u001b[39msize() \u001b[39m==\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()):\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/functional.py?line=3129'>3130</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTarget size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) must be the same as input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()))\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/functional.py?line=3131'>3132</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[39minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[1;31mValueError\u001b[0m: Target size (torch.Size([30])) must be the same as input size (torch.Size([30, 2]))"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    # print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f} ,Test Acc: {test_acc:.4f}')\n",
    "    print(f'Epoch: {epoch}, Loss: {loss}, Train Acc: {train_acc} ,Test Acc: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392bc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5f79af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "# %% Save the model \n",
    "model_type_name=\"100_epoch_0.78 train_acc\"\n",
    "\n",
    "mlflow.pytorch.log_model(model, \"model\") \n",
    "mlflow.end_run()\n",
    "\n",
    "\n",
    "# SAVE MODEL\n",
    "#  pls create a folder named model_saved if not there\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d_%m_%Y %H_%M_%S\")\n",
    "PATH_to_save_model=\"model_saved/\"+\"model_\"+dt_string+\":\"+model_type_name+\".pt\"\n",
    "PATH_to_save_model=\"model_saved/model_tf/model \"+dt_string+model_type_name+\".pt\"\n",
    "torch.save(model, PATH_to_save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9dee0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! shutdown -s -t 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a42cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c875dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d976c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GNNExplainer\n",
    "# Initialize explainer\n",
    "explainer = GNNExplainer(model, epochs=200, return_type='log_prob')\n",
    "graph = train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3f0fedb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 200/200 [00:02<00:00, 66.94it/s]\n"
     ]
    }
   ],
   "source": [
    "node_feat_mask, edge_mask = explainer.explain_graph(graph.x, graph.edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eb419c4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\main2_09_may.ipynb Cell 58'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000074?line=0'>1</a>\u001b[0m ax, G \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mvisualize_subgraph(node_feat_mask, edge_index, edge_mask, y\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49my)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000074?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\models\\explainer.py:287\u001b[0m, in \u001b[0;36mExplainer.visualize_subgraph\u001b[1;34m(self, node_idx, edge_index, edge_mask, y, threshold, edge_y, node_alpha, seed, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/explainer.py?line=283'>284</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/explainer.py?line=284'>285</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnx\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/explainer.py?line=286'>287</a>\u001b[0m \u001b[39massert\u001b[39;00m edge_mask\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/explainer.py?line=288'>289</a>\u001b[0m \u001b[39mif\u001b[39;00m node_idx \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m node_idx \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/explainer.py?line=289'>290</a>\u001b[0m     hard_edge_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mBoolTensor([\u001b[39mTrue\u001b[39;00m] \u001b[39m*\u001b[39m edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m),\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/models/explainer.py?line=290'>291</a>\u001b[0m                                       device\u001b[39m=\u001b[39medge_mask\u001b[39m.\u001b[39mdevice)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ax, G = explainer.visualize_subgraph(node_feat_mask, edge_index, edge_mask, y=data.y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c3771611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feat_mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "55f15f79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\main2_09_may.ipynb Cell 60'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/main2_09_may.ipynb#ch0000076?line=0'>1</a>\u001b[0m G\n",
      "\u001b[1;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f04b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
