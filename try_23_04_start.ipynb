{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932d5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a070583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6647fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import numpy as np \n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f325fd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling \n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "# torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab461a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20d1afae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.11.0\n",
      "Cuda available: True\n",
      "Torch geometric version: 2.0.4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eb90cb",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933b7f1",
   "metadata": {},
   "source": [
    "https://github.com/quarkslab/dataset-call-graph-blogpost-material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd4213",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/17JFlnMUjcsMmXQYXF8xZ3z169VDAwUls?authuser=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42475076",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=QLIkOtKS4os&list=PLV8yxwGOxvvoNkzPfCx2i8an--Tkt7O8Z&index=9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53bbd4",
   "metadata": {},
   "source": [
    "https://github.com/deepfindr/gnn-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0c3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = MoleculeDataset(root=\"data/\", filename=\"HIV_test.csv\", test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35bff41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path_temp= \"dataset-call-graph-blogpost-material/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39810b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data=pickle.load(open(path_temp+\"goodware_graphs.p\",\"rb\"))\n",
    "bad_data=pickle.load(open(path_temp+\"malware_graphs.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "374db08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of array =  546\n",
      "length of 1 item =  2\n",
      "length of first thing in one item =  464\n",
      "length of second thing in one item =  464\n"
     ]
    }
   ],
   "source": [
    "print(\"length of array = \",len(good_data))\n",
    "print(\"length of 1 item = \",len(good_data[0]))\n",
    "print(\"length of first thing in one item = \",len(good_data[0][0]))\n",
    "print(\"length of second thing in one item = \",len(good_data[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a1fde57",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_menu=['mov', 'call', 'lea', 'jmp', 'push', 'add', 'xor', 'cmp', 'int3', 'nop', 'pushl', 'dec', 'sub', 'insl', 'inc','jz', 'jnz', 'je', 'jne', 'ja', 'jna', 'js', 'jns', 'jl', 'jnl', 'jg', 'jng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16078f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, root, filename,good_data, bad_data, test=False, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        root = Where the dataset should be stored. This folder is split\n",
    "        into raw_dir (downloaded dataset) and processed_dir (processed data). \n",
    "        \"\"\"\n",
    "        self.test = test\n",
    "        self.filename = filename\n",
    "        self.good_data=good_data\n",
    "        self.bad_data=bad_data\n",
    "        super(MoleculeDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data_passed=self.good_data+self.bad_data\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
    "            (The download func. is not implemented here)  \n",
    "        \"\"\"\n",
    "        return [\"goodware_graphs.p\",\"malware_graphs.p\"]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n",
    "#         self.data = self.data_passed\n",
    "        return \"NOt implemented yet\"\n",
    "\n",
    "        # if self.test:\n",
    "        #     return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
    "        # else:\n",
    "        #     return [f'data_{i}.pt' for i in list(self.data.index)]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "#         self.data = self.data_passed\n",
    "        print(\"started doing stuff\")\n",
    "        index=0\n",
    "\n",
    "        for mol in (self.good_data):\n",
    "            \n",
    "\n",
    "            feature_data=mol[0]\n",
    "            neighbour_data=mol[1]\n",
    "\n",
    "            # i need to create inst ->index\n",
    "            instr_index=dict()\n",
    "            for a,b in enumerate(feature_data):\n",
    "              instr_index[b]=a \n",
    "\n",
    "            # Get node features\n",
    "            node_feats = self._get_node_features(feature_data,instr_index)\n",
    "            # Get edge features\n",
    "            edge_feats = self._get_edge_features(neighbour_data)\n",
    "#             edge_feats = []\n",
    "            # Get adjacency info\n",
    "            edge_index = self._get_adjacency_info(neighbour_data,instr_index)\n",
    "\n",
    "            # Get labels info\n",
    "            label = 1\n",
    "\n",
    "            # Create data object\n",
    "            data = Data(x=node_feats, \n",
    "                        edge_index=edge_index,\n",
    "                        edge_attr=edge_feats,\n",
    "                        y=label,\n",
    "                        smiles=mol\n",
    "                        ) \n",
    "                        \n",
    "            torch.save(data, \n",
    "                    os.path.join(self.processed_dir, \n",
    "                                 f'data_{index}.pt'))\n",
    "\n",
    "            index+=1\n",
    "        \n",
    "        for mol in (self.bad_data):\n",
    "            \n",
    "\n",
    "            feature_data=mol[0]\n",
    "            neighbour_data=mol[1]\n",
    "\n",
    "            # i need to create inst ->index\n",
    "            instr_index=dict()\n",
    "            for a,b in enumerate(feature_data):\n",
    "              instr_index[b]=a \n",
    "\n",
    "            # Get node features\n",
    "            node_feats = self._get_node_features(feature_data,instr_index)\n",
    "            # Get edge features\n",
    "            edge_feats = self._get_edge_features(neighbour_data)\n",
    "#             edge_feats = []\n",
    "            # Get adjacency info\n",
    "            edge_index = self._get_adjacency_info(neighbour_data,instr_index)\n",
    "\n",
    "            # Get labels info\n",
    "            label = 0\n",
    "\n",
    "            # Create data object\n",
    "            data = Data(x=node_feats, \n",
    "                        edge_index=edge_index,\n",
    "                        edge_attr=edge_feats,\n",
    "                        y=label,\n",
    "                        smiles=mol\n",
    "                        ) \n",
    "                        \n",
    "            torch.save(data, \n",
    "                    os.path.join(self.processed_dir, \n",
    "                                 f'data_{index}.pt'))\n",
    "\n",
    "            index+=1\n",
    "        \n",
    "        \n",
    "\n",
    "    def process_node_features(self,val, node_feature_menu):\n",
    "      # print(\"jj\")\n",
    "      # print(val)\n",
    "      node_out=[]\n",
    "      keys=val.keys()\n",
    "      for name in node_feature_menu : \n",
    "        if(name in keys):\n",
    "          node_out.append(val[name])\n",
    "        else:\n",
    "          node_out.append(0)\n",
    "      return node_out\n",
    "\n",
    "\n",
    "    def _get_node_features(self, node_features,instr_index):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of Nodes, Node Feature size]\n",
    "        \"\"\"\n",
    "        node_feature_menu=['mov', 'call', 'lea', 'jmp', 'push', 'add', 'xor', 'cmp', 'int3', 'nop', 'pushl', 'dec', 'sub', 'insl', 'inc','jz', 'jnz', 'je', 'jne', 'ja', 'jna', 'js', 'jns', 'jl', 'jnl', 'jg', 'jng']\n",
    "\n",
    "        all_node_feats = []\n",
    "\n",
    "        for atom in node_features:\n",
    "            # print(\"atom is\",atom)\n",
    "            \n",
    "            node_feats = []\n",
    "            node_feats = self.process_node_features(node_features[atom],node_feature_menu)\n",
    "            # Append node features to matrix\n",
    "            all_node_feats.append(node_feats)\n",
    "\n",
    "        all_node_feats = np.asarray(all_node_feats)\n",
    "        return torch.tensor(all_node_feats, dtype=torch.float)\n",
    "\n",
    "    def _get_edge_features(self, mol):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of edges, Edge Feature size]\n",
    "        \"\"\"\n",
    "        all_edge_feats = []\n",
    "\n",
    "        # for bond in mol.GetBonds():\n",
    "        #     edge_feats = []\n",
    "        #     # Feature 1: Bond type (as double)\n",
    "        #     edge_feats.append(bond.GetBondTypeAsDouble())\n",
    "        #     # Feature 2: Rings\n",
    "        #     edge_feats.append(bond.IsInRing())\n",
    "        #     # Append node features to matrix (twice, per direction)\n",
    "        #     all_edge_feats += [edge_feats, edge_feats]\n",
    "\n",
    "        all_edge_feats = np.asarray(all_edge_feats)\n",
    "        return torch.tensor(all_edge_feats, dtype=torch.float)\n",
    "\n",
    "    def get_one_instr_adjacency(self,val,instr_index,self_instruction_number):\n",
    "        edge_val=[]\n",
    "        for a in val:\n",
    "            edge_val+=[[instr_index[self_instruction_number],instr_index[a]]]\n",
    "\n",
    "        return edge_val\n",
    "\n",
    "    def _get_adjacency_info(self, mol, instr_index):\n",
    "        \"\"\"\n",
    "        We could also use rdmolops.GetAdjacencyMatrix(mol)\n",
    "        but we want to be sure that the order of the indices\n",
    "        matches the order of the edge features\n",
    "        \"\"\"\n",
    "        edge_indices = []\n",
    "        for bond in mol:\n",
    "            edge_indices += self.get_one_instr_adjacency(mol[bond],instr_index,bond)\n",
    "\n",
    "        edge_indices = torch.tensor(edge_indices)\n",
    "        edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
    "        return edge_indices\n",
    "\n",
    "    def _get_labels(self, label):\n",
    "        label = np.asarray([label])\n",
    "        return torch.tensor(label, dtype=torch.int64)\n",
    "\n",
    "    def len(self):\n",
    "#         return self.data_pass.shape[0]\n",
    "        return len(self.data_passed)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
    "            - Is not needed for PyG's InMemoryDataset\n",
    "        \"\"\"\n",
    "        data = torch.load(os.path.join(self.processed_dir, \n",
    "                             f'data_{idx}.pt'))\n",
    "        return data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fbe3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started doing stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MoleculeDataset(root=\"data/\", filename=\"goodware_graphs.p\", good_data=good_data, bad_data=bad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac9ec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1222, 27], edge_index=[2, 3265], edge_attr=[0], y=0, smiles=[2])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a02df057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1, 437],\n",
      "        [  2,   4],\n",
      "        [  3, 412],\n",
      "        ...,\n",
      "        [491, 142],\n",
      "        [491, 289],\n",
      "        [491, 135]])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[1].edge_index.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b7d446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [11.,  0.,  2.,  ...,  0.,  0.,  0.],\n",
      "        [ 7.,  4.,  2.,  ...,  0.,  0.,  0.],\n",
      "        [26., 10.,  0.,  ...,  0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b859ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cut_dataset=train_dataset[526:566]\n",
    "train_cut_dataset= train_dataset[:526]+train_dataset[566:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5f8dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "#%% Prepare training\n",
    "NUM_GRAPHS_PER_BATCH = 10\n",
    "# NUM_GRAPHS_PER_BATCH = 1\n",
    "\n",
    "train_loader = DataLoader(train_cut_dataset, \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True,\n",
    "                         num_workers=0)\n",
    "# test_loader = DataLoader(test_dataset, \n",
    "#                          batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test_cut_dataset, \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a1087",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69ffcaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU\n",
    "from torch_geometric.nn import TransformerConv, GATConv, TopKPooling, BatchNorm\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn.conv.x_conv import XConv\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(GNN, self).__init__()\n",
    "        num_classes = 2\n",
    "        embedding_size = 1024\n",
    "\n",
    "        # GNN layers\n",
    "        self.conv1 = GATConv(feature_size, embedding_size, heads=3, dropout=0.3)\n",
    "        self.head_transform1 = Linear(embedding_size*3, embedding_size)\n",
    "        self.pool1 = TopKPooling(embedding_size, ratio=0.8)\n",
    "        self.conv2 = GATConv(embedding_size, embedding_size, heads=3, dropout=0.3)\n",
    "        self.head_transform2 = Linear(embedding_size*3, embedding_size)\n",
    "        self.pool2 = TopKPooling(embedding_size, ratio=0.5)\n",
    "        self.conv3 = GATConv(embedding_size, embedding_size, heads=3, dropout=0.3)\n",
    "        self.head_transform3 = Linear(embedding_size*3, embedding_size)\n",
    "        self.pool3 = TopKPooling(embedding_size, ratio=0.2)\n",
    "\n",
    "        # Linear layers\n",
    "        self.linear1 = Linear(embedding_size*2, 1024)\n",
    "        self.linear2 = Linear(1024, num_classes)  \n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "        # First block\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.head_transform1(x)\n",
    "\n",
    "        x, edge_index, edge_attr, batch_index, _, _ = self.pool1(x, \n",
    "                                                        edge_index, \n",
    "                                                        None, \n",
    "                                                        batch_index)\n",
    "        x1 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "        # Second block\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.head_transform2(x)\n",
    "        x, edge_index, edge_attr, batch_index, _, _ = self.pool2(x, \n",
    "                                                        edge_index, \n",
    "                                                        None, \n",
    "                                                        batch_index)\n",
    "        x2 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "        # Third block\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.head_transform3(x)\n",
    "        x, edge_index, edge_attr, batch_index, _, _ = self.pool3(x, \n",
    "                                                        edge_index, \n",
    "                                                        None, \n",
    "                                                        batch_index)\n",
    "        x3 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "        # Concat pooled vectors\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        # Output block\n",
    "        x = self.linear1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ccdbe958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
    "    accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# from dataset_featurizer import MoleculeDataset\n",
    "# from model import GNN\n",
    "import mlflow.pytorch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "00a30ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%% Loss and Optimizer\n",
    "# # new one \n",
    "\n",
    "# # weights = torch.tensor([1, 20], dtype=torch.float32).to(device)\n",
    "# # loss_fn = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# weight2 = torch.tensor([BEST_PARAMETERS[\"pos_weight\"]], dtype=torch.float32).to(device)\n",
    "# loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=weight2)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=BEST_PARAMETERS['learning_rate'], momentum=BEST_PARAMETERS['sgd_momentum'], weight_decay=BEST_PARAMETERS[\"weight_decay\"])  \n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=BEST_PARAMETERS[\"scheduler_gamma\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10927db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 17945602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (conv1): GATConv(27, 1024, heads=3)\n",
       "  (head_transform1): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "  (pool1): TopKPooling(1024, ratio=0.8, multiplier=1.0)\n",
       "  (conv2): GATConv(1024, 1024, heads=3)\n",
       "  (head_transform2): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "  (pool2): TopKPooling(1024, ratio=0.5, multiplier=1.0)\n",
       "  (conv3): GATConv(1024, 1024, heads=3)\n",
       "  (head_transform3): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "  (pool3): TopKPooling(1024, ratio=0.2, multiplier=1.0)\n",
       "  (linear1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (linear2): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Loading the model\n",
    "model = GNN(feature_size=train_dataset[0].x.shape[1]) \n",
    "model = model.to(device)\n",
    "print(f\"Number of parameters: {count_parameters(model)}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9addbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Loss and Optimizer\n",
    "# original\n",
    "weights = torch.tensor([1, 3], dtype=torch.float32).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.8)  \n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2e5e0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()        \n",
    "# loss, hidden = model(data, hidden, targets)\n",
    "# loss.backward()\n",
    "clip_value=10\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9689160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)  \n",
    "        pred = model(batch.x.float(), \n",
    "                        batch.edge_attr.float(),\n",
    "                        batch.edge_index, \n",
    "                        batch.batch) \n",
    "        loss = torch.sqrt(loss_fn(pred, batch.y))    \n",
    "        all_preds.append(np.argmax(pred.cpu().detach().numpy(), axis=1))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"test\")\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calculate_metrics(y_pred, y_true, epoch, type):\n",
    "    print(f\"\\n Confusion matrix: \\n {confusion_matrix(y_pred, y_true)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_pred, y_true)}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_pred, y_true)}\")\n",
    "    print(f\"Precision: {precision_score(y_pred, y_true)}\")\n",
    "    print(f\"Recall: {recall_score(y_pred, y_true)}\")\n",
    "    try:\n",
    "        roc = roc_auc_score(y_pred, y_true)\n",
    "        print(f\"ROC AUC: {roc}\")\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(roc), step=epoch)\n",
    "    except:\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(0), step=epoch)\n",
    "        print(f\"ROC AUC: notdefined\")\n",
    "        \n",
    "    try:\n",
    "        mlflow.log_metric(key=f\"accuracy-{type}\", value=float(accuracy_score(y_pred, y_true)), step=epoch)\n",
    "    except:\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(0), step=epoch)\n",
    "        print(f\"Accuracy: notdefined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e09eaccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    # Enumerate over the data\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for _, batch in enumerate(tqdm(train_loader)):\n",
    "        # Use GPU\n",
    "        batch.to(device)  \n",
    "        # Reset gradients\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        # Passing the node features and the connection info\n",
    "        pred = model(batch.x.float(), \n",
    "                                batch.edge_attr.float(),\n",
    "                                batch.edge_index, \n",
    "                                batch.batch) \n",
    "        # Calculating the loss and gradients\n",
    "#         loss = torch.sqrt(loss_fn(pred, batch.y)) \n",
    "        loss_v1 = loss_fn(pred, batch.y) \n",
    "        loss_v2=torch.sqrt(loss_v1)\n",
    "#         print(\"batch.y\")\n",
    "#         print(batch.y)\n",
    "        \n",
    "#         print(\"pred\")\n",
    "#         print(pred)\n",
    "        \n",
    "#         print(\"loss_v1\")\n",
    "#         print(loss_v1)\n",
    "#         print(\"loss_v2\")\n",
    "#         print(loss_v2)\n",
    "        \n",
    "        loss=loss_v2\n",
    "        loss.backward()  \n",
    "        # Update using the gradients\n",
    "        optimizer.step()  \n",
    "\n",
    "        all_preds.append(np.argmax(pred.cpu().detach().numpy(), axis=1))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac796c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 4/133 [00:40<21:44, 10.12s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 4.00 GiB total capacity; 1.89 GiB already allocated; 0 bytes free; 2.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\try_23_04_start.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000032?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000032?line=3'>4</a>\u001b[0m     \u001b[39m# Training\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000032?line=4'>5</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000032?line=5'>6</a>\u001b[0m     loss \u001b[39m=\u001b[39m train(epoch\u001b[39m=\u001b[39;49mepoch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000032?line=6'>7</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000032?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | Train Loss \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\code\\OELP_bigger\\try_23_04_start.ipynb Cell 32'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000031?line=19'>20</a>\u001b[0m \u001b[39m#         print(\"batch.y\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000031?line=20'>21</a>\u001b[0m \u001b[39m#         print(batch.y)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000031?line=21'>22</a>\u001b[0m         \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000031?line=27'>28</a>\u001b[0m \u001b[39m#         print(\"loss_v2\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000031?line=28'>29</a>\u001b[0m \u001b[39m#         print(loss_v2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000031?line=30'>31</a>\u001b[0m         loss\u001b[39m=\u001b[39mloss_v2\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000031?line=31'>32</a>\u001b[0m         loss\u001b[39m.\u001b[39;49mbackward()  \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000031?line=32'>33</a>\u001b[0m         \u001b[39m# Update using the gradients\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000031?line=33'>34</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mstep()  \n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 4.00 GiB total capacity; 1.89 GiB already allocated; 0 bytes free; 2.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Run the training\n",
    "with mlflow.start_run() as run:\n",
    "    for epoch in range(50):\n",
    "        # Training\n",
    "        model.train()\n",
    "        loss = train(epoch=epoch)\n",
    "        loss = loss.detach().cpu().numpy()\n",
    "        print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
    "        mlflow.log_metric(key=\"Train loss\", value=float(loss), step=epoch)\n",
    "\n",
    "        # Testing\n",
    "        model.eval()\n",
    "        if epoch % 5 == 0:\n",
    "            loss = test(epoch=epoch)\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            print(f\"Epoch {epoch} | Test Loss {loss}\")\n",
    "            mlflow.log_metric(key=\"Test loss\", value=float(loss), step=epoch)\n",
    "\n",
    "        scheduler.step()\n",
    "print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249975e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'variables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\try_23_04_start.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000071?line=0'>1</a>\u001b[0m \u001b[39m# cuda run out of space problem\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000071?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgc\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000071?line=2'>3</a>\u001b[0m \u001b[39mdel\u001b[39;00m variables\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000071?line=3'>4</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'variables' is not defined"
     ]
    }
   ],
   "source": [
    "# # cuda run out of space problem\n",
    "# import gc\n",
    "# del variables\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9157e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92973361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/04/23 15:31:12 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\JERRYJ~1\\AppData\\Local\\Temp\\tmp5sdh5yz_\\model\\data, flavor: pytorch), fall back to return ['torch==1.11.0', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback.\n",
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelInfo(artifact_path='model', flavors={'pytorch': {'model_data': 'data', 'pytorch_version': '1.11.0', 'code': None}, 'python_function': {'pickle_module_name': 'mlflow.pytorch.pickle_module', 'loader_module': 'mlflow.pytorch', 'python_version': '3.9.12', 'data': 'data', 'env': 'conda.yaml'}}, model_uri='runs:/cc21dc71c0534040841e16dbca0e94bc/model', model_uuid='0b947a31a40446c39570297bbf4897d7', run_id='cc21dc71c0534040841e16dbca0e94bc', saved_input_example_info=None, signature_dict=None, utc_time_created='2022-04-23 10:00:57.036793', mlflow_version='1.25.1')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# %% Save the model \n",
    "mlflow.pytorch.log_model(model, \"model\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9e10b",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe88f2",
   "metadata": {},
   "source": [
    "![asd](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16f4bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_name=\"findr_gcn_model1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8d30cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "abb55567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "#  pls create a folder named model_saved if not there\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d_%m_%Y %H_%M_%S\")\n",
    "PATH_to_save_model=\"model_saved/\"+\"model_\"+dt_string+\":\"+model_type_name+\".pt\"\n",
    "PATH_to_save_model=\"model_saved/model \"+dt_string+\".pt\"\n",
    "torch.save(model, PATH_to_save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "262852dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (conv1): GATConv(27, 27, heads=3)\n",
       "  (head_transform1): Linear(in_features=81, out_features=27, bias=True)\n",
       "  (pool1): TopKPooling(27, ratio=0.8, multiplier=1.0)\n",
       "  (conv2): GATConv(27, 27, heads=3)\n",
       "  (head_transform2): Linear(in_features=81, out_features=27, bias=True)\n",
       "  (pool2): TopKPooling(27, ratio=0.5, multiplier=1.0)\n",
       "  (conv3): GATConv(27, 27, heads=3)\n",
       "  (head_transform3): Linear(in_features=81, out_features=27, bias=True)\n",
       "  (pool3): TopKPooling(27, ratio=0.2, multiplier=1.0)\n",
       "  (linear1): Linear(in_features=54, out_features=1024, bias=True)\n",
       "  (linear2): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Model class must be defined somewhere\n",
    "# model2 = torch.load(PATH_to_save_model)\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeebab9",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "866555a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling \n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size, model_params):\n",
    "        super(GNN, self).__init__()\n",
    "        embedding_size = model_params[\"model_embedding_size\"]\n",
    "        n_heads = model_params[\"model_attention_heads\"]\n",
    "        self.n_layers = model_params[\"model_layers\"]\n",
    "        dropout_rate = model_params[\"model_dropout_rate\"]\n",
    "        top_k_ratio = model_params[\"model_top_k_ratio\"]\n",
    "        # self.top_k_every_n = model_params[\"model_top_k_every_n\"]\n",
    "        self.top_k_every_n = 1\n",
    "        dense_neurons = model_params[\"model_dense_neurons\"]\n",
    "        edge_dim = model_params[\"model_edge_dim\"]\n",
    "\n",
    "        self.conv_layers = ModuleList([])\n",
    "        self.transf_layers = ModuleList([])\n",
    "        self.pooling_layers = ModuleList([])\n",
    "        self.bn_layers = ModuleList([])\n",
    "\n",
    "        # Transformation layer\n",
    "        self.conv1 = TransformerConv(feature_size, \n",
    "                                    embedding_size, \n",
    "                                    heads=n_heads, \n",
    "                                    dropout=dropout_rate,\n",
    "                                    edge_dim=edge_dim,\n",
    "                                    beta=True) \n",
    "\n",
    "        self.transf1 = Linear(embedding_size*n_heads, embedding_size)\n",
    "        self.bn1 = BatchNorm1d(embedding_size)\n",
    "\n",
    "        # Other layers\n",
    "        for i in range(self.n_layers):\n",
    "            self.conv_layers.append(TransformerConv(embedding_size, \n",
    "                                                    embedding_size, \n",
    "                                                    heads=n_heads, \n",
    "                                                    dropout=dropout_rate,\n",
    "                                                    edge_dim=edge_dim,\n",
    "                                                    beta=True))\n",
    "\n",
    "            self.transf_layers.append(Linear(embedding_size*n_heads, embedding_size))\n",
    "            self.bn_layers.append(BatchNorm1d(embedding_size))\n",
    "            \n",
    "            # this is me doing shit\n",
    "            # print(self.top_k_every_n)\n",
    "            if i % self.top_k_every_n == 0:\n",
    "                self.pooling_layers.append(TopKPooling(embedding_size, ratio=top_k_ratio))\n",
    "            \n",
    "\n",
    "        # Linear layers\n",
    "        self.linear1 = Linear(embedding_size*2, dense_neurons)\n",
    "        self.linear2 = Linear(dense_neurons, int(dense_neurons/2))  \n",
    "        self.linear3 = Linear(int(dense_neurons/2), 1)  \n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "        # Initial transformation\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = torch.relu(self.transf1(x))\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        # Holds the intermediate graph representations\n",
    "        global_representation = []\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.conv_layers[i](x, edge_index, edge_attr)\n",
    "            x = torch.relu(self.transf_layers[i](x))\n",
    "            x = self.bn_layers[i](x)\n",
    "            # Always aggregate last layer\n",
    "            if i % self.top_k_every_n == 0 or i == self.n_layers:\n",
    "                x , edge_index, edge_attr, batch_index, _, _ = self.pooling_layers[int(i/self.top_k_every_n)](\n",
    "                    x, edge_index, edge_attr, batch_index\n",
    "                    )\n",
    "                # Add current representation\n",
    "                global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))\n",
    "    \n",
    "        x = sum(global_representation)\n",
    "\n",
    "        # Output block\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d0a2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% imports \n",
    "import torch \n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
    "    accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify tracking server\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    # for pp in model.parameters():\n",
    "    #     print(\"------------\")\n",
    "    #     print(pp==null)\n",
    "    #     print(pp)\n",
    "    #     print(pp.requires_grad)\n",
    "    #     print(pp.numel())\n",
    "    #     print(\"------------\")\n",
    "\n",
    "\n",
    "    # return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return 1\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch, model, train_loader, optimizer, loss_fn):\n",
    "    # Enumerate over the data\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for _, batch in enumerate(tqdm(train_loader)):\n",
    "        # Use GPU\n",
    "        batch.to(device)  \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        # Passing the node features and the connection info\n",
    "        pred = model(batch.x.float(), \n",
    "                                batch.edge_attr.float(),\n",
    "                                batch.edge_index, \n",
    "                                batch.batch) \n",
    "        # Calculating the loss and gradients\n",
    "        loss = loss_fn(torch.squeeze(pred), batch.y.float())\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
    "    return running_loss/step\n",
    "\n",
    "def test(epoch, model, test_loader, loss_fn):\n",
    "    all_preds = []\n",
    "    all_preds_raw = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)  \n",
    "        pred = model(batch.x.float(), \n",
    "                        batch.edge_attr.float(),\n",
    "                        batch.edge_index, \n",
    "                        batch.batch) \n",
    "        loss = loss_fn(torch.squeeze(pred), batch.y.float())\n",
    "\n",
    "         # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_preds_raw.append(torch.sigmoid(pred).cpu().detach().numpy())\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    print(all_preds_raw[0][:10])\n",
    "    print(all_preds[:10])\n",
    "    print(all_labels[:10])\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"test\")\n",
    "    log_conf_matrix(all_preds, all_labels, epoch)\n",
    "    return running_loss/step\n",
    "\n",
    "def log_conf_matrix(y_pred, y_true, epoch):\n",
    "    # Log confusion matrix as image\n",
    "    cm = confusion_matrix(y_pred, y_true)\n",
    "    classes = [\"0\", \"1\"]\n",
    "    df_cfm = pd.DataFrame(cm, index = classes, columns = classes)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    cfm_plot = sns.heatmap(df_cfm, annot=True, cmap='Blues', fmt='g')\n",
    "    cfm_plot.figure.savefig(f'data/images/cm_{epoch}.png')\n",
    "    mlflow.log_artifact(f\"data/images/cm_{epoch}.png\")\n",
    "\n",
    "def calculate_metrics(y_pred, y_true, epoch, type):\n",
    "    print(f\"\\n Confusion matrix: \\n {confusion_matrix(y_pred, y_true)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_pred, y_true)}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_pred, y_true)}\")\n",
    "    prec = precision_score(y_pred, y_true)\n",
    "    rec = recall_score(y_pred, y_true)\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    mlflow.log_metric(key=f\"Precision-{type}\", value=float(prec), step=epoch)\n",
    "    mlflow.log_metric(key=f\"Recall-{type}\", value=float(rec), step=epoch)\n",
    "    try:\n",
    "        roc = roc_auc_score(y_pred, y_true)\n",
    "        print(f\"ROC AUC: {roc}\")\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(roc), step=epoch)\n",
    "    except:\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(0), step=epoch)\n",
    "        print(f\"ROC AUC: notdefined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a328c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mango import scheduler, Tuner\n",
    "\n",
    "# # Search space\n",
    "# param_space = dict(x=range(-10,10))\n",
    "\n",
    "# # Quadratic objective Function\n",
    "# @scheduler.serial\n",
    "# def objective(x):\n",
    "#     return x * x\n",
    "\n",
    "# # Initialize and run Tuner\n",
    "# tuner = Tuner(param_space, objective)\n",
    "# results = tuner.minimize()\n",
    "\n",
    "# print(f'Optimal value of parameters: {results[\"best_params\"]} and objective: {results[\"best_objective\"]}')\n",
    "# # => Optimal value of parameters: {'x': 0}  and objective: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b78f3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Run the training\n",
    "from mango import scheduler, Tuner\n",
    "from config import HYPERPARAMETERS, BEST_PARAMETERS, SIGNATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eab04a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def run_one_training(params):\n",
    "    params = params[0]\n",
    "    with mlflow.start_run() as run:\n",
    "        # Log parameters used in this experiment\n",
    "        for key in params.keys():\n",
    "            mlflow.log_param(key, params[key])\n",
    "\n",
    "        # Loading the dataset\n",
    "        print(\"Loading dataset...\")\n",
    "        train_dataset = MoleculeDataset(root=\"data/\", filename=\"goodware_graphs.p\", good_data=good_data, bad_data=bad_data)\n",
    "        test_cut_dataset=train_dataset[526:566]\n",
    "        train_cut_dataset= train_dataset[:526]+train_dataset[566:]\n",
    "\n",
    "        # params[\"model_edge_dim\"] = train_dataset[0].edge_attr.shape[1]\n",
    "        params[\"model_edge_dim\"] = 0\n",
    "\n",
    "        # Prepare training\n",
    "        train_loader = DataLoader(test_cut_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "        test_loader = DataLoader(train_cut_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "\n",
    "        # Loading the model\n",
    "        print(\"Loading model...\")\n",
    "        model_params = {k: v for k, v in params.items() if k.startswith(\"model_\")}\n",
    "        print(\"printing init mdoel params\")\n",
    "        for par in model_params:\n",
    "            print(par)\n",
    "        model = GNN(feature_size=train_dataset[0].x.shape[1], model_params=model_params) \n",
    "        model = model.to(device)\n",
    "        print(f\"Number of parameters: {count_parameters(model)}\")\n",
    "        mlflow.log_param(\"num_params\", count_parameters(model))\n",
    "\n",
    "        # < 1 increases precision, > 1 recall\n",
    "        weight = torch.tensor([params[\"pos_weight\"]], dtype=torch.float32).to(device)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), \n",
    "                                    lr=params[\"learning_rate\"],\n",
    "                                    momentum=params[\"sgd_momentum\"],\n",
    "                                    weight_decay=params[\"weight_decay\"])\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=params[\"scheduler_gamma\"])\n",
    "        \n",
    "        # Start training\n",
    "        best_loss = 1000\n",
    "        early_stopping_counter = 0\n",
    "        for epoch in range(300): \n",
    "            if early_stopping_counter <= 10: # = x * 5 \n",
    "                # Training\n",
    "                model.train()\n",
    "                loss = train_one_epoch(epoch, model, train_loader, optimizer, loss_fn)\n",
    "                print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
    "                mlflow.log_metric(key=\"Train loss\", value=float(loss), step=epoch)\n",
    "\n",
    "                # Testing\n",
    "                model.eval()\n",
    "                if epoch % 5 == 0:\n",
    "                    loss = test(epoch, model, test_loader, loss_fn)\n",
    "                    print(f\"Epoch {epoch} | Test Loss {loss}\")\n",
    "                    mlflow.log_metric(key=\"Test loss\", value=float(loss), step=epoch)\n",
    "                    \n",
    "                    # Update best loss\n",
    "                    if float(loss) < best_loss:\n",
    "                        best_loss = loss\n",
    "                        # Save the currently best model \n",
    "                        mlflow.pytorch.log_model(model, \"model\", signature=SIGNATURE)\n",
    "                        early_stopping_counter = 0\n",
    "                    else:\n",
    "                        early_stopping_counter += 1\n",
    "\n",
    "                scheduler.step()\n",
    "            else:\n",
    "                print(\"Early stopping due to no improvement.\")\n",
    "                return [best_loss]\n",
    "    print(f\"Finishing training with best test loss: {best_loss}\")\n",
    "    return [best_loss]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b418f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hyperparameter search...\n",
      "Loading dataset...\n",
      "started doing stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "printing init mdoel params\n",
      "model_top_k_ratio\n",
      "model_top_k_every_n\n",
      "model_layers\n",
      "model_embedding_size\n",
      "model_dropout_rate\n",
      "model_dense_neurons\n",
      "model_attention_heads\n",
      "model_edge_dim\n",
      "1\n",
      "1\n",
      "1\n",
      "Number of parameters: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:32<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [82452] at index 0 does not match the shape of the indexed tensor [0] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\try_23_04_start.ipynb Cell 49'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000048?line=4'>5</a>\u001b[0m config[\u001b[39m\"\u001b[39m\u001b[39mnum_iteration\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000048?line=6'>7</a>\u001b[0m tuner \u001b[39m=\u001b[39m Tuner(HYPERPARAMETERS, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000048?line=7'>8</a>\u001b[0m               objective\u001b[39m=\u001b[39mrun_one_training,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000048?line=8'>9</a>\u001b[0m               conf_dict\u001b[39m=\u001b[39mconfig) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000048?line=9'>10</a>\u001b[0m results \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39;49mminimize()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\mango\\tuner.py:153\u001b[0m, in \u001b[0;36mTuner.minimize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=150'>151</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=151'>152</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaximize_objective \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=152'>153</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\mango\\tuner.py:140\u001b[0m, in \u001b[0;36mTuner.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=137'>138</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=138'>139</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_bayesian:\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=139'>140</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunBayesianOptimizer()\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=140'>141</a>\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_random:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=141'>142</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunRandomOptimizer()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\mango\\tuner.py:182\u001b[0m, in \u001b[0;36mTuner.runBayesianOptimizer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=178'>179</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrunBayesianOptimizer\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=179'>180</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=181'>182</a>\u001b[0m     X_list, Y_list, X_tried \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_initial()\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=184'>185</a>\u001b[0m     \u001b[39m# evaluated hyper parameters are used\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=185'>186</a>\u001b[0m     X_init \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds\u001b[39m.\u001b[39mconvert_GP_space(X_list)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\mango\\tuner.py:163\u001b[0m, in \u001b[0;36mTuner.run_initial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=159'>160</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=160'>161</a>\u001b[0m     \u001b[39m# getting first few random values\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=161'>162</a>\u001b[0m     X_tried \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds\u001b[39m.\u001b[39mget_random_sample(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39minitial_random)\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=162'>163</a>\u001b[0m     X_list, Y_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunUserObjective(X_tried)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=164'>165</a>\u001b[0m     \u001b[39m# in case initial random results are invalid try different samples\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=165'>166</a>\u001b[0m     n_tries \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\mango\\tuner.py:334\u001b[0m, in \u001b[0;36mTuner.runUserObjective\u001b[1;34m(self, X_next_PS)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=330'>331</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrunUserObjective\u001b[39m(\u001b[39mself\u001b[39m, X_next_PS):\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=331'>332</a>\u001b[0m     \u001b[39m# initially assuming entire X_next_PS is evaluated and returned results are only Y values\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=332'>333</a>\u001b[0m     X_list_evaluated \u001b[39m=\u001b[39m X_next_PS\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=333'>334</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjective_function(X_next_PS)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=334'>335</a>\u001b[0m     Y_list_evaluated \u001b[39m=\u001b[39m results\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/mango/tuner.py?line=336'>337</a>\u001b[0m     \u001b[39m# if result is a tuple, then there is possibility that partial values are evaluated\u001b[39;00m\n",
      "\u001b[1;32md:\\code\\OELP_bigger\\try_23_04_start.ipynb Cell 48'\u001b[0m in \u001b[0;36mrun_one_training\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000047?line=44'>45</a>\u001b[0m \u001b[39mif\u001b[39;00m early_stopping_counter \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m10\u001b[39m: \u001b[39m# = x * 5 \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000047?line=45'>46</a>\u001b[0m     \u001b[39m# Training\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000047?line=46'>47</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000047?line=47'>48</a>\u001b[0m     loss \u001b[39m=\u001b[39m train_one_epoch(epoch, model, train_loader, optimizer, loss_fn)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000047?line=48'>49</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | Train Loss \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000047?line=49'>50</a>\u001b[0m     mlflow\u001b[39m.\u001b[39mlog_metric(key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain loss\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m(loss), step\u001b[39m=\u001b[39mepoch)\n",
      "\u001b[1;32md:\\code\\OELP_bigger\\try_23_04_start.ipynb Cell 45'\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(epoch, model, train_loader, optimizer, loss_fn)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000044?line=42'>43</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad() \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000044?line=43'>44</a>\u001b[0m \u001b[39m# Passing the node features and the connection info\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000044?line=44'>45</a>\u001b[0m pred \u001b[39m=\u001b[39m model(batch\u001b[39m.\u001b[39;49mx\u001b[39m.\u001b[39;49mfloat(), \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000044?line=45'>46</a>\u001b[0m                         batch\u001b[39m.\u001b[39;49medge_attr\u001b[39m.\u001b[39;49mfloat(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000044?line=46'>47</a>\u001b[0m                         batch\u001b[39m.\u001b[39;49medge_index, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000044?line=47'>48</a>\u001b[0m                         batch\u001b[39m.\u001b[39;49mbatch) \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000044?line=48'>49</a>\u001b[0m \u001b[39m# Calculating the loss and gradients\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000044?line=49'>50</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(torch\u001b[39m.\u001b[39msqueeze(pred), batch\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mfloat())\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\code\\OELP_bigger\\try_23_04_start.ipynb Cell 44'\u001b[0m in \u001b[0;36mGNN.forward\u001b[1;34m(self, x, edge_attr, edge_index, batch_index)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000043?line=72'>73</a>\u001b[0m \u001b[39m# Always aggregate last layer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000043?line=73'>74</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtop_k_every_n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000043?line=74'>75</a>\u001b[0m     x , edge_index, edge_attr, batch_index, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpooling_layers[\u001b[39mint\u001b[39;49m(i\u001b[39m/\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtop_k_every_n)](\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000043?line=75'>76</a>\u001b[0m         x, edge_index, edge_attr, batch_index\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000043?line=76'>77</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000043?line=77'>78</a>\u001b[0m     \u001b[39m# Add current representation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000043?line=78'>79</a>\u001b[0m     global_representation\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mcat([gmp(x, batch_index), gap(x, batch_index)], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\pool\\topk_pool.py:167\u001b[0m, in \u001b[0;36mTopKPooling.forward\u001b[1;34m(self, x, edge_index, edge_attr, batch, attn)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/pool/topk_pool.py?line=163'>164</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiplier \u001b[39m*\u001b[39m x \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiplier \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/pool/topk_pool.py?line=165'>166</a>\u001b[0m batch \u001b[39m=\u001b[39m batch[perm]\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/pool/topk_pool.py?line=166'>167</a>\u001b[0m edge_index, edge_attr \u001b[39m=\u001b[39m filter_adj(edge_index, edge_attr, perm,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/pool/topk_pool.py?line=167'>168</a>\u001b[0m                                    num_nodes\u001b[39m=\u001b[39;49mscore\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m))\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/pool/topk_pool.py?line=169'>170</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x, edge_index, edge_attr, batch, perm, score[perm]\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\pool\\topk_pool.py:71\u001b[0m, in \u001b[0;36mfilter_adj\u001b[1;34m(edge_index, edge_attr, perm, num_nodes)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/pool/topk_pool.py?line=67'>68</a>\u001b[0m row, col \u001b[39m=\u001b[39m row[mask], col[mask]\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/pool/topk_pool.py?line=69'>70</a>\u001b[0m \u001b[39mif\u001b[39;00m edge_attr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/pool/topk_pool.py?line=70'>71</a>\u001b[0m     edge_attr \u001b[39m=\u001b[39m edge_attr[mask]\n\u001b[0;32m     <a href='file:///d%3A/Anaconda3/envs/pytorch/lib/site-packages/torch_geometric/nn/pool/topk_pool.py?line=72'>73</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack([row, col], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), edge_attr\n",
      "\u001b[1;31mIndexError\u001b[0m: The shape of the mask [82452] at index 0 does not match the shape of the indexed tensor [0] at index 0"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Hyperparameter search\n",
    "print(\"Running hyperparameter search...\")\n",
    "config = dict()\n",
    "config[\"optimizer\"] = \"Bayesian\"\n",
    "config[\"num_iteration\"] = 100\n",
    "\n",
    "tuner = Tuner(HYPERPARAMETERS, \n",
    "              objective=run_one_training,\n",
    "              conf_dict=config) \n",
    "results = tuner.minimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6186c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config[\"optimizer\"] = \"Bayesian\"\n",
    "config[\"num_iteration\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0eba2bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=3\n",
    "x==None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f276b28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\try_23_04_start.ipynb Cell 51'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000049?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model2\u001b[39m.\u001b[39mparameters():\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000049?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(p)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "for p in model2.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8244d325",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\OELP_bigger\\try_23_04_start.ipynb Cell 51'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/OELP_bigger/try_23_04_start.ipynb#ch0000050?line=0'>1</a>\u001b[0m \u001b[39m5\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "5%0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159972c",
   "metadata": {},
   "source": [
    "# Model 3 : Sage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c725236",
   "metadata": {},
   "source": [
    "* https://medium.com/analytics-vidhya/ohmygraphs-graphsage-in-pyg-598b5ec77e7b\n",
    "* https://towardsdatascience.com/introduction-to-graphsage-in-python-a9e7f9ecf9d7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='.', name=\"Pubmed\")\n",
    "data = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a9fa3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Pubmed()\n",
      "-------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 19717\n",
      "Number of features: 500\n",
      "Number of classes: 3\n",
      "\n",
      "Graph:\n",
      "------\n",
      "Training nodes: 60\n",
      "Evaluation nodes: 500\n",
      "Test nodes: 1000\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print information about the dataset\n",
    "print(f'Dataset: {dataset}')\n",
    "print('-------------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# Print information about the graph\n",
    "print(f'\\nGraph:')\n",
    "print('------')\n",
    "print(f'Training nodes: {sum(data.train_mask).item()}')\n",
    "print(f'Evaluation nodes: {sum(data.val_mask).item()}')\n",
    "print(f'Test nodes: {sum(data.test_mask).item()}')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f026c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_planets=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a221fd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19a2f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train_dataset\n",
    "data=train_cut_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "507f8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data_planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df7a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
